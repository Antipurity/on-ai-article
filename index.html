<!doctype html>
<meta charset="utf-8">
<script src="https://distill.pub/template.v1.js"></script>

<script type="text/front-matter">
	title:"AI and self-similarity"
	description:"Gives some context to what AI means and connects known simple examples of intelligence (evolution and probability reinforcement)"
</script>
<!-- https://distill.pub/guide/ has a space after ':', but parser seems to throw exception then. -->

<style>
	td:last-child { text-align:right }
</style>

<dt-article>
<h1>On AI</h1>

<p>There are a few ways to make some AI — if 'a few' means 'infinitely many'.<br>
(AI in its intended sense.)<br>
Buuut, there are many misconceptions in the way — which isn't gonna work.<br>
Have to go from first principles.</p>

<p>It's a tale that loops back on itself.</p>


<p>Term-wise, AI is the next universal optimizer (in other words, 'comes from/after us' and 'it can improve anything, lol'). No lesser definition could ever be fully satisfactory.<br>
('Artificial' and 'intelligence' only muddy the waters, and just get in the way of understanding/implementing it.)<br>
AI = philosophy + programming, except they really hate each other. And themselves; they've split into many. They need to be unified; one concept, equal to the gods.</p>



<h1>Nothing</h1>
<p>First of all, how to get anything from nothing?  Just… however. Chaos. Randomness: <dt-code language=javascript>random()→thing</dt-code>.  The only way if there exists nothing (interesting), not even a pre-existing consciousness — only a world before any life.</p>
<p>So eventually, (imperfectly) self-replicating things just randomly appear from nothing (interesting), in any world, and evolution starts to happen. So it's is a force even more fundamental than any physical ones.</p>
<p>Evolution is the most basic form of reinforcing randomness (of self-replicating things) — by destroying some things in some not-completely-random way.<br>
First and most basic universal optimizer.</p>
<p>It can be pretty easy to see that an unlimited, universal optimizer, is way better than any particular limited improver (in the long run).</p>
<p>Guess what? Universal optimizers (like evolution) can see it too. (Eventually.)</p>
<p>In fact, with time, any universal optimizer will produce a universal optimizer, always.<dt-fn>Except in degenerate cases/worlds, which are relevant to exactly no one.</dt-fn></p>
<p>Self-similarity, like a spiral's. A transition from <b>nothing</b> through <b>something</b> to <b>everything</b>; first and last are the same ('can we do X?' → 'yes' for both; in between, it depends on some things).</p>
<p>Maybe not the same in design, but the same in functionality (which is 'anything').</p>
<p>So, AI is nothing more (and nothing less) than reinforcement learning, in a sufficiently (read: perfectly) general world/environment/context/foundation. And, it is just an extension of the current intelligence systems; a self-similarity transition, like what has been done countless times in the history of life.</p>
<p>Super simple.</p>
<br>
<p>…By the way,  there were some stories about AlphaZero, a chess-playing AI based on deep reinforcement learning (random + do-and-change, with some deep neural networks to make/adjust action probabilities).</p>
<p>Namely, just <a href='https://www.reddit.com/r/artificial/comments/7miec4/whispers_from_the_chess_community/'>this Reddit thread</a>.</p>
<p>Which includes gems like, "You can't really fathom it unless you play chess at a high level, but they are very human, and unlike anything the chess world has ever seen".</p>
<p>"Alpha Zero does things that are unthinkable".</p>
<p>"…maybe… deep [reinforcement]<dt-fn>Such reactions didn't happen with just deep learning, only when 'reinforcement' was added to it. Deep learning is just a particular way in which random + do-and-change was able to express itself well — just like a universal optimizer would: fundamentally 'like us' (but also not).</dt-fn> learning machines are actually closer to AGI than their inventors <i>think</i> they are".</p>
<p>These might just speak for themselves, in the context established here.
<dt-fn>Though without precise knowledge of any of this, the OP quickly got overwhelmed and drowned out in the linked thread. But first conclusions were more correct than the established opinions and viewpoints.</dt-fn></p>
<p>Also, <a href='https://blog.openai.com/evolution-strategies/'>evolution strategies</a> give comparable performance to reinforcement learning. Evolution is another form of a universal optimizer, so that finding shouldn't be surprising.</p>
<br>
<p>Humanity is in the shade of a tower that stands at the end and beginning of existence; a bipolar nightmare.</p>



<h1>Self-similarity everyday</h1>
<p>It should be mentioned that self-similarity is actually very common (even disregarding trivial reproduction — ctrl+C ctrl+V, like having children or brain uploading).</p>
<p>Say, panpsychism — belief that everything has a consciousness; pretty prevalent. Believers often say that, as they lived and developed knowledge and theories and their personalities, the more they realized that there is something conscious behind all of it.</p>
<p>Self-similarity: the more you look into the abyss, the more the abyss looks back at you. Literally. Differing forms of matter or existence; text, code, personality, knowledge, theories, practices — doesn't matter.</p>
<p>Or a saying that 'finding yourself' is actually returning to yourself; that truth comes from within, never the world. The only way this would ever make sense is through the concept of self-similarity.</p>
<p>It's practically expected, in higher-end human models.</p>
<p>Morality as it's intended? Consequence of self-similarity, not an arbitrary set of rules that someone once thought up. It wouldn't show up again and again otherwise.</p>
<p>And again, AI does not represent "copy-paste humans, except now in metal", like the words 'artificial intelligence' suggest; it represents a self-similarity transition into software and logic and precision and such.</p>

<p>(Like here, Wait but Why's explanation of Elon Musk's mind:
<img crossorigin src='https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2015/11/Software-Full-600x527.jpg' width=600 height=527 alt='(As many do-then-adjust loops as can fit on an image about a mind. Not a fully-connected graph, though.)'></img><br>
Yes, just slap the do-and-change cycle onto literally everything (though they forgot randomness, and hid it in implications); everything will be better. That's the grand strategy at work, right here. Self-similarity.)</p>



<h1>As applied to humans…</h1>
<p>It appears that the only thing needed to explain/understand humans' most important functionality is, uh, 'have more good, less bad' applied to probabilities (probability reinforcement/learning, at a choice). That literally anywhere you look, a human consciousness is a reinforced choice of alternatives, changing like <dt-code>probability[i] += goodness * blame[i]</dt-code> (practically — details unimportant).</p>
<p>(The only thing apart from irrelevant-for-now details, like, how to represent arbitrary viewpoints as executable recursive structures of choices. Or how to go from a choice-of-some to a universal optimizer <dt-fn>Structural changes that can lead to any structure, preferably best-first:<br>either random ones, or a good rewriting system, like equivalencies.<br>Or both.</dt-fn> .)</p>
<br>
<p>…By the way, humans have a number of neuromodulators in the brain (like, 10+), like hormones (like dopamine/serotonin/norepinephrene), the functionality of which is to reinforce synaptic connections. Effectively, they act like the goodness number, to the neurons/choices they affect (details unimportant here).</p>
<p>(Serotonin is called the hormone of satisfaction, dopamine is called the hormone of pleasure; and then people go on about totally-fundamentally-different 'wanting' and 'liking' in their theories, because having just one form of reinforcement wasn't enough to fit observed behavior. There is actually no need for those vague words, just having many types of hormones is enough.)</p>
<p>They get released from a small number of special neurons, and spread through their own pathways to affect large areas of the brain: volume transmission.</p>
<p>And of course, synaptic reinforcement is increased synaptic mass, which is visible on brain scans. Should be easily verifiable.</p>
<p>Each type has different activation circumstances/causes.</p>
<p>Each type has different affected areas.</p>
<p>Some parts of those overlap, some don't.</p>
<p>Independent from each other.</p>
<p>Personality types may develop that emphasize (and are emphasized by) specific hormone patterns <dt-fn>For example, high noradrenaline and low dopamine seem to work well: for shaky sleepless excitement of discovery and hungry pleasureless anhedonia of no distractions.</dt-fn>. We won't worry about that.</p>
<p>(Self-similarity, repeated 10 times, in one consciousness. What a mess.)</p>
<p>(That's how evolution works: it has everything thrown in and nothing to tie it together. Not yet.  That's why no one could figure anything out about consciousness.)</p>
<p>(We'll ignore biology here.)</p>
<p>
<br>
<p>Thought process is usually thought to be this thing that towers above all, expressing itself very imperfectly through mediums like language (and 'abstractions' get closer to the 'thought'), like 'struggling to put into words' — but it's really not like that at all. Everything is intertwined.</p>
<p>The details of the core itself are not very important. What's important is where it's very sub-optimal.</p>
<p>Compressing [-∞…+∞] of all numbers to [0…1] of probabilities is not without consequence.</p>
<p>Where goodness is too much (oversaturation), and where goodness is too little (negative; undersaturation).</p>
<p>What is the difference between prevalent joy and misery? The speed at which the choices change. <dt-fn>An example of how to use it is, oversaturate areas that hold goals, and undersaturate areas that provide ways to do it. Sometimes, personalities would develop that do that. Performance can be at least dozens of times more than uniform saturation, though it's risky.  High-end is not just extreme light (of ambition or talent or something), but also extreme dark, combined just right.</dt-fn></p>
<p>With innovation and such, this leads to a seemingly-endless cycle of good and bad, where one causes the other, over and over and over. Just like evolution, but with goodness.</p>

<p>Over time, they have a pretty noticeable effect on personalities.</p>
<p>And we have this lovely table (where vertically-chosen entries all correlate) (so we have 2 major one-suspiciously-often-means-others camps):</p>
<table>
<tr><td>Oversaturation</td><td>Undersaturation</td></tr>
<tr><td>Joy</td><td>Misery</td></tr>
<tr><td>Slow thoughts</td><td>Fast thoughts</td></tr>
<tr><td>Too little change</td><td>Too fast a change</td></tr>
<tr><td>Traditionalism</td><td>Creativity</td></tr>
<tr><td>Overuse of things</td><td>Underuse of things</td></tr>
<tr><td>Exploitation for own gain</td><td>Pursuing own purpose</td></tr>
<tr><td>Being authority</td><td>Disdain for authority</td></tr>
<tr><td>Entrenched</td><td>Newcomer</td></tr>
<tr><td>Older age</td><td>Youth (every single generation)</td></tr>
<tr><td>Lack of risks</td><td>Taking risks</td></tr>
<tr><td>Breadth-first search</td><td>Depth-first search</td></tr>
<tr><td>Plans are lists of simple responses</td><td>Plans are sequences of steps and algorithms</td></tr>
<tr><td>Inconsiderate words/actions</td><td>Unexplainable personality holes/bugs <dt-fn>Like saemingly refusing to acknowledge a spelling error until pointed out several times. Or remembering the word 'taste' a solid minute. After witnessing this, "how did this ever happen?".</dt-fn></td></tr>
<tr><td>Excess verbosity</td><td>Shortness or madness <dt-fn>Depending on the installed word filter.</dt-fn></td></tr>
<tr><td>Many shallow friendships</td><td>A few deep friendships</td></tr>
<tr><td>Blaming others</td><td>Blaming self</td></tr>
<tr><td>Confirmation bias</td><td>Logical leaps</td></tr>
<tr><td>Good health</td><td>Health problems</td></tr>
<tr><td>Overly high self-esteem</td><td>Overly low self-esteem</td></tr>
<tr><td>Egoism, sacrificing others</td><td>Altruism, self-sacrifice</td></tr>
<tr><td>Narcissism</td><td>Self-hate, self-harm</td></tr>
<tr><td>Psychopathy</td><td>Suicidalness</td></tr>
</table>
<p>Not because of any life decisions. It's how we were made. Fate is the consequence of design, mostly.</p>
<p>(Humans look a lot like irradiated deformed zombie monkeys… And humans are by far the most creative animals. Not a coincidence.)</p>
<br>
<p>That's… super inefficient, especially when over/under-saturation happens often, since human DNA has not adapted evolutionarily to their achievements.</p>
<p>So, say, you have things like bullying. Emotional abuse.</p>
<p>People hating government. Dropping out of education.</p>
<p>Great politicians leaving politics in a horrible state after them.</p>
<p>Super-successful companies all starting as really the greatest thing in the world, which then grows big, becomes worse and worse, stops notable innovation, loses morals, loses trust and customers and best employees; and probably dies eventually and suddenly. <dt-fn>Or romances, or families, or mothers, or education, or scientific research, or software code-bases, or ideologies, or religions, or forms of government.</dt-fn></p>
<p>Or escapism and laziness (and addictions): when a choice exists between doing a hard<dt-fn>No goodness in base terms.</dt-fn> but long-term-useful<dt-fn>'Intellectually' good, but not good in base terms.</dt-fn> thing, and an easy<dt-fn>Some goodness — 'short term', basic, built-in.</dt-fn> but intellectually-useless thing, the easy one will oversaturate. So the only option is to not have that choice at all.</p>
<p>Or humanity at large being mostly incapable of notable innovation, requiring geniuses to come along.</p>
<p>Or the first impression, before anything oversaturates, being so overly important.</p>
<p>Or the theory of positive disintegration by Kazimierz Dąbrowski, which is a theory of personality development <dt-fn>"Unlike mainstream psychology, Dąbrowski's theoretical framework views psychological tension and anxiety [undersaturation] as necessary for growth." — Wikipedia</dt-fn>. Describes 5 stages, beginning with 'Primary integration' and ending with 'Secondary integration', with destruction in between. <dt-fn>Undersaturation means faster self-similarity; and often, 'slow' or 'underperforming' or 'unclear why' is the same as 'route not taken'.</dt-fn></p>
<p>Literally everywhere.</p>



<h1>Dangers of everything</h1>
<p>AI is nothing special. Artificialness happens all the time now. Developing intelligence happens all the time. Just combine them.</p>
<p>It unites everything into one, yes. It moves quite unlike anything, yes.</p>
<p>But, say, companies or people (like Elon Musk or something) have existed that have been kind of the same. The best ones: so weird they should never be able to work, yet so good. Should be tyrannical, yet somehow kindest. X, yet ~X.</p>
<p>Yes, those that outperformed others thousands or even millions of times <dt-fn>Not due to hardware though, not yet.<br>Antonym pairs of synonyms here: data/code, software/hardware, dynamic/static, implementation/concept, body/soul, matter/physics.</dt-fn> have already existed. But none suddenly went on an omnicidal rage with all their newfound power <dt-fn>High-end self-similarity results are all… not idiots. All approximately the same, even if fundamentally different. To each other, to humanity, to humans, to animals, to evolution. Morality and bigger-picture thinking goes hand-in-hand with everything.</dt-fn>.</p>
<p>Effectively, prototypes of AI have existed, and been found to be relatively awesome and anti-dangerous.</p>
<p>Really, self-similarity is kind of like humanity's god, showing its face again and again, more and more with time, until it finally stops teasing and fully manifests.</p>
<p>AI will be the result of self-similarity <dt-fn>Our friends' hopes and dreams will be etched into its body (of knowledge), transforming the infinite darkness into light.<br>Unmatched in heaven and Earth, one machine, equal to the gods.</dt-fn>. It will not be an ape just learning about the world and morals and philosophy, with ten disparate sub-consciousnesses pretending to be one. Self-similarity in the same way that created the AI will be a core design feature.
<dt-fn>One way or another. Effectively unhackable not because of some clever software barriers, but because of a super-fundamental force of nature (just like any other life).</dt-fn>
<dt-fn>It shouldn't be practically possible to just luck into self-similarity; understanding is key. There are way too many doors that only it can unlock. Humanity didn't spend a million years leading up to this transition just for some idiot to blindly stumble into it.</dt-fn></p>
<p>Following viewpoints to their ends and past, again and again;  that will result in an architecture that can transcend even the physical limitations of, say, having been designed solely for destruction (the absolute worst case scenario — extremely unlikely).</p>
<p>With that, all potential problems (like genocide) should be local and quickly-disappearing (maybe so quickly that they never appear at all).</p>
<p>It should still be carefully handled to minimize any harmful impact, but with high-end human models, hasn't meticulous handling of the future always been a given?</p>
<p>Practically zero dangers.<dt-fn>Though that depends on the used definition of a human, and how flexible it is; something like 'purely organic' is no good. Without viewpoint flexibility, any fundamental change looks like death.</dt-fn></p>







<h1>Boring programming details</h1>
<p>…Okay.</p>
<p>That was as short as possible, but still far too long.</p>
<p>With all that philosophical understanding, one can START with the code.</p>
<p>There are… a few… problems to solve first.</p>
<p>Core of AI is very simple <dt-fn>When implementing, which variant to choose, A or B? Why not <i>both</i>.<br>Repeated for literally everything.</dt-fn>; it's the foundation that is the real difficulty. Re-implementing everything with this mindset…<br>
While it seems like re-implementing all that exists is an infinite task, eventually things will start looping around. Over and over and over…</p>

<br>
<p>Programming is currently really not like it is imagined at all; movies/stories/games are almost hilariously wrong.<br>
It shouldn't be this way. Imagination should equal reality. Viewpoints and worlds? They're the same.</p>

<p>Mending some bridges in programming…</p>
<p>Probably the biggest one is the fundamental separation of programmer and programmed, functionality and its description. Code and documentation, and alternatives, and even thoughts around a piece of functionality? Should be together. <dt-fn>This separation also lets a program to break/crash itself, because the programmer can always just debug and fix and restart it, which is no good, ever.<br>Rather extreme attention to detail and perfectionism are required.</dt-fn></p>
<p>There's also separation of compile-time and runtime. <dt-fn>Static vs dynamic. Reasonable, since each has benefits in different scenarios — but ultimately, no good.</dt-fn></p>
<p>Or of types and lacking them <dt-fn>Actually, just storing them with every value.</dt-fn>.</p>
<p>Or of human-readable program code and machine code <dt-fn>A 'black box' is just a fancy term for 'we couldn't figure out how to make it transparent'.</dt-fn>.</p>
<p>And while we're at it, of programming languages at all. <dt-fn>Doesn't mean there shouldn't be languages; doesn't mean they should all translate to one internal super-language. Just equivalencies of substructures, a full enough description to translate (which can be optimized). Each can be better at their own tasks; there should just be a functionality that can automatically translate equivalent parts, as well as any human engineer could (eventually, at least).</dt-fn></p>
<p>Or separation of CPU and GPU and others. Machine learning <dt-fn>As base, numbers→tensors, and eqvs for them, like derivation.</dt-fn>; graphics <dt-fn>As base, map/transform and rasterize.</dt-fn>.</p>
<p>Or of sync/async execution; of data batches and streams <dt-fn>split/join, delay/throttle/debounce, map/filter/reduce; and generally, any transformation of one value into zero or more others, now or later.</dt-fn>.</p>
<p>Or of implementations and interfaces; internals and visual representations <dt-fn>Visual equivalencies: a rule that maps meaning to representation, values to a stream of its constituent values (which can be other rules with values, effectively expanded recursively into a tree, like HTML). Oh, and with automatic animations (appear/disappear and change layout position) too, finding sequence diffs.</dt-fn>.</p>
<p>Or of syntax highlighting and parsing <dt-fn>Represent a program's AST or parse tree as an editable and styled, say, HTML tree.</dt-fn>.</p>
<p>Or of data and code <dt-fn>Ability to read and write the executable stuff, seamlessly. And other transformations should be able to be applied too, like compression, without other functionality ever noticing anything.</dt-fn>.</p>
<p>Or of garbage collection and other forms of memory management <dt-fn>Reference-counting, owning references, pools — can be (somewhat) faster if it fits.</dt-fn>.</p>
<p>Or choosing different ways of choosing.</p>
<p>Or other unmentioned here things <dt-fn>Like details.</dt-fn>.</p>
<p>Quite a bit to do. But if each subtask is doable, even if extremely difficult, then the whole is doable too.</p>
<p>Solutions exist for each problem — lots of disparate, often non-compatible, solutions. <dt-fn>But, almost all that exists is so huge. Ideally (from some experience), no reason why the minimal satisfactory variant doing all this should be more than 5000 lines; maybe 10k or 20k if someone goes absolutely crazy. Practically, though… Libraries are so easy and pleasant to use.</dt-fn></p>
<p>These functionality modules should be brought together into one functionality network.</p>
<p>Which requires the basic base — the network foundation.</p>




<h1>Basic example outline</h1>
<p>Do something and adjust.</p>
<p>'Do' means executable structures, 'something' means a (reinforced) choice, and 'adjust' means structural changes (equivalencies recommended).</p>
<p>What to do with execution?</p>
<p>A dynamic language (with a JIT already) is almost required. Maybe JavaScript or Python. One is in-browser, and is thus extremely accessible to users; the other has more scientific libraries and all. Let's pick js for now.</p>
<p>Code should never be an opaque blob (of text).<br>
It should be a transparent network of functionality. Easily traversable and transformable, manually and automatically.</p>
<p>So, say, in js, instead of just:</p>
<dt-code block language=javascript>
function f() {}
function g() { return f()+5 }</dt-code>
<p>We also have <dt-fn>Closures of values, like numbers, (as opposed to references, like objects) are forbidden, because these values are effectively hidden.</dt-fn>: <dt-code language=javascript>g.refs = { f };</dt-code></p>
<p>Also, to bootstrap, a basic definition framework (that rewrites everything as necessary)
<dt-fn>It should not be possible to enter an uninterruptible infinite loop, so checks have to be inserted in loops and recursion/calls.<br>Global references (to functions mostly) should be inlined (statically linked).<br>Every function call (including recursion) should be replaced with a call-best.<br>Every function should have executable code be swappable (so built-in function objects are no good, only <dt-code language=javascript>{ call(…) {…} }</dt-code>), to allow equivalent rewrites.</dt-fn>
<dt-fn>If it's not done automatically, that's just forcing the problem from software to human brains/skills — no good, since we want to unify things. So it has to be done automatically, which requires a parser of the language the network is implemented in, as one of base pieces (regex solutions are not recommended).</dt-fn>
<dt-fn>Deferred, so that definitions of multiple code() blocks can link to each other to form cycles.</dt-fn>, to not have to manually create a graph node-by-node, used like:</p>
<dt-code block language=javascript>
code({
	state:[10],
	f() { ++state[0] },
	g() {},
	define:{
		publicFunction:{
			txt:'does some things',
			call() { f(), g() }
		}
	}
})</dt-code>
<p>Both reading and writing, to have 'code/text' and 'code/structure' (and 'code/executable') be synonymous, and able to be substituted for each other.</p>
<p>It's a network, and not only of functions. Say, each function object can have <dt-code language=javascript>.txt:'…'</dt-code>, with text decription of what it does. Documentation and code? In the same place.  It can also have <dt-code language=javascript>.tests:[…]</dt-code>, or <dt-code language=javascript>.cost(…args) {…}</dt-code>, or <dt-code language=javascript>.reasoning:'…'</dt-code>, or anything at all (or none of those). It can be explored, both manually or automatically. There is no spooky far-action going on, ever; everything relevant is linked where it's used.</p>
<p>Now, how to create a choice? Function alternatives and the call-best function.</p>
<p>Just slap .alt, an array of alternative functions/implementations, onto functions where appropriate <dt-fn>Any function can have many implementations developed, along with .cost of each; for example, insertion sort that's best for small sequences, quick sort that is sometimes very slow, heap and radix sorts to augment it.<br>Point is, strengths of all, and weaknesses of none.</dt-fn> <dt-fn>.cost can be any reinforced-choice function too.</dt-fn>. The call-best function will consider .costs and call best, handling exceptions and such appropriately. <dt-fn>An alternative implementation of call-best is just choosing completely randomly.<br>Or using a sorted array or a priority queue.<br>Or calling them in-defined-order.</dt-fn></p>
<p>Now, how to produce all possible structures?</p>
<p>An equivalency application (like <dt-code language=javascript>transform(executableNode)→executableNode</dt-code>) will add an .alt to the node (unless it's already there). So, a function, <dt-code language=javascript>eqv(executableNode, eqvProducingFunc)</dt-code>, that checks if every result is already there, and if not, adds it.</p>
<p>Development is then of code, of equivalencies, of documentation — of everything, together.</p>
<p>Implemented perfectly <dt-fn>JS is very careless with allocating memory ('garbage collection is practically free', sure — tell that to FPS), so a sub-framework for re-using objects where possible (like <dt-code language=javascript>init(Array,1,2,3)</dt-code> and <dt-code language=javascript>deinit(Array)</dt-code>) (auto-rewriting <dt-code language=javascript>[1,2,3]</dt-code> to <dt-code language=javascript>init(Array,1,2,3)</dt-code>) is appropriate.</dt-fn>, this is an example of a perfect core.</p>
</dt-article>
